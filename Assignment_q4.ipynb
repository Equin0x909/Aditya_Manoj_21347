{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ad061-929e-49cf-93c5-5f732b9f3f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data\\train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 182040794/182040794 [00:54<00:00, 3319170.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ./data\\test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 64275384/64275384 [00:23<00:00, 2685971.69it/s]\n",
      "C:\\Users\\adima\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adima\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\adima/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 528M/528M [02:01<00:00, 4.54MB/s]\n",
      "C:\\Users\\adima\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\adima/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:07<00:00, 6.67MB/s]\n",
      "C:\\Users\\adima\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\adima/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 97.8M/97.8M [00:15<00:00, 6.59MB/s]\n",
      "C:\\Users\\adima\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to C:\\Users\\adima/.cache\\torch\\hub\\checkpoints\\resnet101-63fe2227.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 171M/171M [00:16<00:00, 10.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LeNet-5, Epoch [1/10], Loss: 2.1333, Accuracy: 23.40%\n",
      "Model: LeNet-5, Epoch [2/10], Loss: 1.6489, Accuracy: 43.41%\n",
      "Model: LeNet-5, Epoch [3/10], Loss: 1.4025, Accuracy: 52.98%\n",
      "Model: LeNet-5, Epoch [4/10], Loss: 1.2535, Accuracy: 58.12%\n",
      "Model: LeNet-5, Epoch [5/10], Loss: 1.1598, Accuracy: 61.75%\n",
      "Model: LeNet-5, Epoch [6/10], Loss: 1.0883, Accuracy: 63.93%\n",
      "Model: LeNet-5, Epoch [7/10], Loss: 1.0403, Accuracy: 65.55%\n",
      "Model: LeNet-5, Epoch [8/10], Loss: 0.9943, Accuracy: 66.87%\n",
      "Model: LeNet-5, Epoch [9/10], Loss: 0.9642, Accuracy: 68.00%\n",
      "Model: LeNet-5, Epoch [10/10], Loss: 0.9434, Accuracy: 68.64%\n",
      "Training finished for LeNet-5\n",
      "Test Accuracy for LeNet-5: 76.24%\n",
      "Performance Report for LeNet-5:\n",
      "--------------------------------------------------\n",
      "Test Accuracy: 76.24%\n",
      "Precision: 0.7475\n",
      "Recall: 0.7393\n",
      "F1-score: 0.7360\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: VGG-16, Epoch [1/10], Loss: 2.4777, Accuracy: 16.89%\n",
      "Model: VGG-16, Epoch [2/10], Loss: 2.2516, Accuracy: 18.14%\n",
      "Model: VGG-16, Epoch [3/10], Loss: 2.2472, Accuracy: 18.60%\n",
      "Model: VGG-16, Epoch [4/10], Loss: 2.2454, Accuracy: 18.49%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import SVHN\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import csv\n",
    "\n",
    "# Step 1: Load the SVHN dataset\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = SVHN(root='./data', split='train', transform=train_transform, download=True)\n",
    "test_dataset = SVHN(root='./data', split='test', transform=test_transform, download=True)\n",
    "\n",
    "# Use a subset of the dataset (25%)\n",
    "train_subset = Subset(train_dataset, range(0, len(train_dataset), 4))\n",
    "\n",
    "# Step 2: Preprocess the dataset\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Step 3: Choose pretrained models\n",
    "# Implement LeNet-5 manually\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "pretrained_models = {\n",
    "    'LeNet-5': LeNet5(),\n",
    "    'VGG-16': models.vgg16(pretrained=True),\n",
    "    'ResNet-18': models.resnet18(pretrained=True),\n",
    "    'ResNet-50': models.resnet50(pretrained=True),\n",
    "    'ResNet-101': models.resnet101(pretrained=True)\n",
    "}\n",
    "\n",
    "# Step 4: Load the pretrained weights for the chosen model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Step 5: Fine-tune the model on the SVHN dataset\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize CSV writer\n",
    "with open('model_metrics.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Model', 'Test Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "\n",
    "    for model_name, model in pretrained_models.items():\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Training loop with data augmentation and adjusted hyperparameters\n",
    "        model.train()  # Set model to training mode\n",
    "    \n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Track the loss and accuracy\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Print statistics every epoch\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            epoch_acc = correct / total * 100\n",
    "            \n",
    "            print(f\"Model: {model_name}, Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "    \n",
    "        print(\"Training finished for\", model_name)\n",
    "    \n",
    "        # Evaluate the model on the test set\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                predicted_labels.extend(predicted.cpu().numpy())\n",
    "                true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "        test_accuracy = correct / total * 100\n",
    "        print(f\"Test Accuracy for {model_name}: {test_accuracy:.2f}%\")\n",
    "    \n",
    "        # Calculate precision, recall, and F1-score\n",
    "        precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "        recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "        f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    \n",
    "        # Write to CSV\n",
    "        writer.writerow([model_name, test_accuracy, precision, recall, f1])\n",
    "    \n",
    "        # Performance report\n",
    "        print(f\"Performance Report for {model_name}:\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-score: {f1:.4f}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print()\n",
    "\n",
    "print(\"Output saved to model_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e633aa58-c5da-4495-ace0-396de247f2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
